"""
Malware Detection and Classification Module for GhidraInsight

This module provides comprehensive malware detection and classification capabilities,
including behavioral analysis, signature matching, ML-based detection, and threat
intelligence integration.

Author: GhidraInsight Team
License: Apache 2.0
"""

import hashlib
import json
import logging
import os
import re
import tempfile
import time
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

logger = logging.getLogger(__name__)


class MalwareFamily(Enum):
    """Known malware families"""

    RANSOMWARE = "ransomware"
    TROJAN = "trojan"
    WORM = "worm"
    ROOTKIT = "rootkit"
    BACKDOOR = "backdoor"
    SPYWARE = "spyware"
    ADWARE = "adware"
    BOTNET = "botnet"
    CRYPTOMINER = "cryptominer"
    LOADER = "loader"
    DROPPER = "dropper"
    RAT = "rat"  # Remote Access Trojan
    INFOSTEALER = "infostealer"
    BANKER = "banker"
    APT = "apt"  # Advanced Persistent Threat
    UNKNOWN = "unknown"


class ThreatLevel(Enum):
    """Threat severity levels"""

    BENIGN = "benign"
    SUSPICIOUS = "suspicious"
    MALICIOUS = "malicious"
    CRITICAL = "critical"


class DetectionMethod(Enum):
    """Methods used for detection"""

    SIGNATURE = "signature"
    HEURISTIC = "heuristic"
    BEHAVIORAL = "behavioral"
    ML_MODEL = "ml_model"
    YARA = "yara"
    THREAT_INTEL = "threat_intel"
    SANDBOX = "sandbox"


@dataclass
class IoC:
    """Indicator of Compromise"""

    ioc_type: str  # "hash", "ip", "domain", "url", "mutex", "registry", "file_path"
    value: str
    description: str
    confidence: float = 0.8
    source: Optional[str] = None
    first_seen: Optional[float] = None
    last_seen: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class BehaviorPattern:
    """Behavioral pattern observed in malware"""

    pattern_id: str
    pattern_type: str  # "api_sequence", "network", "file_operation", "registry"
    description: str
    indicators: List[str] = field(default_factory=list)
    severity: str = "medium"
    mitre_technique: Optional[str] = None  # MITRE ATT&CK technique


@dataclass
class MalwareDetection:
    """Results of malware detection analysis"""

    sample_hash: str
    threat_level: ThreatLevel
    malware_families: List[str] = field(default_factory=list)
    detection_methods: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    iocs: List[IoC] = field(default_factory=list)
    behaviors: List[BehaviorPattern] = field(default_factory=list)
    capabilities: List[str] = field(default_factory=list)
    packer_detected: Optional[str] = None
    obfuscated: bool = False
    anti_analysis: List[str] = field(default_factory=list)
    network_indicators: Dict[str, Any] = field(default_factory=dict)
    file_indicators: Dict[str, Any] = field(default_factory=dict)
    yara_matches: List[Dict[str, Any]] = field(default_factory=list)
    mitre_tactics: List[str] = field(default_factory=list)
    timestamp: float = field(default_factory=time.time)


@dataclass
class MalwareConfig:
    """Configuration for malware detection"""

    enable_yara: bool = True
    enable_ml_detection: bool = True
    enable_behavioral: bool = True
    enable_threat_intel: bool = True
    yara_rules_dir: Optional[str] = None
    threat_intel_feeds: List[str] = field(default_factory=list)
    ml_model_path: Optional[str] = None
    confidence_threshold: float = 0.7
    max_analysis_time: int = 300  # seconds


class MalwareDetector:
    """
    Main malware detection and classification engine.
    """

    def __init__(self, config: Optional[MalwareConfig] = None):
        self.config = config or MalwareConfig()
        self.yara_rules = None
        self.ml_model = None
        self.threat_intel_cache: Dict[str, Any] = {}
        self.known_packers = self._initialize_packer_signatures()
        self.behavior_patterns = self._initialize_behavior_patterns()
        self.anti_analysis_techniques = self._initialize_anti_analysis_patterns()

        # Initialize components
        if self.config.enable_yara:
            self._load_yara_rules()

        if self.config.enable_ml_detection:
            self._load_ml_model()

    def _initialize_packer_signatures(self) -> Dict[str, Dict[str, Any]]:
        """Initialize known packer signatures"""
        return {
            "upx": {
                "entropy": (7.0, 8.0),
                "sections": ["UPX0", "UPX1"],
                "signature": b"UPX!",
            },
            "themida": {
                "entropy": (7.5, 8.0),
                "sections": [".themida"],
                "strings": ["Themida", "Oreans"],
            },
            "vmprotect": {
                "entropy": (7.2, 8.0),
                "sections": [".vmp0", ".vmp1"],
                "strings": ["VMProtect"],
            },
            "aspack": {
                "entropy": (7.0, 7.8),
                "sections": [".aspack", ".adata"],
                "signature": b"ASPack",
            },
            "pecompact": {
                "entropy": (7.0, 7.9),
                "sections": ["PECompact2"],
            },
        }

    def _initialize_behavior_patterns(self) -> List[BehaviorPattern]:
        """Initialize known malicious behavior patterns"""
        return [
            BehaviorPattern(
                pattern_id="ransomware_crypto",
                pattern_type="api_sequence",
                description="Ransomware encryption behavior",
                indicators=[
                    "CryptAcquireContext",
                    "CryptGenKey",
                    "CryptEncrypt",
                    "FindFirstFile",
                    "FindNextFile",
                ],
                severity="critical",
                mitre_technique="T1486",
            ),
            BehaviorPattern(
                pattern_id="keylogger",
                pattern_type="api_sequence",
                description="Keylogging behavior",
                indicators=[
                    "SetWindowsHookEx",
                    "GetAsyncKeyState",
                    "GetKeyboardState",
                ],
                severity="high",
                mitre_technique="T1056.001",
            ),
            BehaviorPattern(
                pattern_id="process_injection",
                pattern_type="api_sequence",
                description="Process injection technique",
                indicators=[
                    "OpenProcess",
                    "VirtualAllocEx",
                    "WriteProcessMemory",
                    "CreateRemoteThread",
                ],
                severity="critical",
                mitre_technique="T1055",
            ),
            BehaviorPattern(
                pattern_id="credential_dumping",
                pattern_type="api_sequence",
                description="Credential theft",
                indicators=[
                    "LsaEnumerateLogonSessions",
                    "LsaGetLogonSessionData",
                    "SamConnect",
                ],
                severity="critical",
                mitre_technique="T1003",
            ),
            BehaviorPattern(
                pattern_id="persistence_registry",
                pattern_type="registry",
                description="Registry persistence mechanism",
                indicators=[
                    r"Software\\Microsoft\\Windows\\CurrentVersion\\Run",
                    r"Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce",
                ],
                severity="high",
                mitre_technique="T1547.001",
            ),
            BehaviorPattern(
                pattern_id="network_c2",
                pattern_type="network",
                description="Command and control communication",
                indicators=[
                    "connect",
                    "send",
                    "recv",
                    "InternetOpenA",
                    "HttpSendRequest",
                ],
                severity="high",
                mitre_technique="T1071",
            ),
        ]

    def _initialize_anti_analysis_patterns(self) -> Dict[str, List[str]]:
        """Initialize anti-analysis technique patterns"""
        return {
            "anti_debug": [
                "IsDebuggerPresent",
                "CheckRemoteDebuggerPresent",
                "NtQueryInformationProcess",
                "OutputDebugString",
            ],
            "anti_vm": [
                "VMware",
                "VirtualBox",
                "QEMU",
                "Bochs",
                "Xen",
                "Hyper-V",
                "cpuid",
            ],
            "anti_sandbox": [
                "Sleep",
                "GetTickCount",
                "QueryPerformanceCounter",
                "mouse_event",
                "GetCursorPos",
            ],
            "anti_disassembly": [
                "self-modifying code",
                "dynamic unpacking",
                "obfuscated control flow",
            ],
        }

    def _load_yara_rules(self):
        """Load YARA rules for signature-based detection"""
        if not self.config.yara_rules_dir:
            logger.warning("YARA rules directory not configured")
            return

        try:
            import yara

            rules_path = Path(self.config.yara_rules_dir)
            if rules_path.exists():
                # Compile all YARA rules in directory
                rule_files = {}
                for rule_file in rules_path.glob("*.yar"):
                    rule_files[rule_file.stem] = str(rule_file)

                if rule_files:
                    self.yara_rules = yara.compile(filepaths=rule_files)
                    logger.info(f"Loaded {len(rule_files)} YARA rule files")
            else:
                logger.warning(f"YARA rules directory not found: {rules_path}")
        except ImportError:
            logger.warning(
                "YARA-python not installed. Install with: pip install yara-python"
            )
        except Exception as e:
            logger.error(f"Error loading YARA rules: {e}")

    def _load_ml_model(self):
        """Load machine learning model for detection"""
        if not self.config.ml_model_path:
            logger.warning("ML model path not configured")
            return

        try:
            # Placeholder for ML model loading
            # In production, this would load a trained model (sklearn, tensorflow, pytorch)
            logger.info("ML model loading not yet implemented")
            # self.ml_model = joblib.load(self.config.ml_model_path)
        except Exception as e:
            logger.error(f"Error loading ML model: {e}")

    def analyze_sample(
        self,
        file_path: str,
        file_data: Optional[bytes] = None,
        ghidra_analysis: Optional[Dict[str, Any]] = None,
    ) -> MalwareDetection:
        """
        Perform comprehensive malware analysis on a sample.

        Args:
            file_path: Path to the file to analyze
            file_data: Optional raw file data
            ghidra_analysis: Optional results from Ghidra static analysis

        Returns:
            MalwareDetection object with analysis results
        """
        start_time = time.time()

        # Read file if data not provided
        if not file_data:
            with open(file_path, "rb") as f:
                file_data = f.read()

        # Calculate hashes
        md5 = hashlib.md5(file_data).hexdigest()
        sha256 = hashlib.sha256(file_data).hexdigest()

        logger.info(f"Analyzing sample: {sha256}")

        # Initialize detection result
        detection = MalwareDetection(
            sample_hash=sha256,
            threat_level=ThreatLevel.BENIGN,
            confidence_score=0.0,
        )

        # Add hash IoCs
        detection.iocs.append(
            IoC(ioc_type="hash_md5", value=md5, description="MD5 hash of sample")
        )
        detection.iocs.append(
            IoC(
                ioc_type="hash_sha256",
                value=sha256,
                description="SHA256 hash of sample",
            )
        )

        # Run detection methods
        if self.config.enable_yara:
            self._detect_with_yara(file_data, detection)

        if self.config.enable_behavioral and ghidra_analysis:
            self._detect_behavioral(ghidra_analysis, detection)

        if self.config.enable_threat_intel:
            self._check_threat_intel(sha256, md5, detection)

        if self.config.enable_ml_detection:
            self._detect_with_ml(file_data, ghidra_analysis, detection)

        # Detect packers
        self._detect_packer(file_data, detection)

        # Detect anti-analysis techniques
        self._detect_anti_analysis(file_data, ghidra_analysis, detection)

        # Extract capabilities
        self._extract_capabilities(ghidra_analysis, detection)

        # Classify malware family
        self._classify_malware(detection)

        # Calculate final threat level and confidence
        self._calculate_threat_level(detection)

        elapsed_time = time.time() - start_time
        logger.info(
            f"Analysis complete in {elapsed_time:.2f}s: {detection.threat_level.value} "
            f"(confidence: {detection.confidence_score:.2%})"
        )

        return detection

    def _detect_with_yara(self, file_data: bytes, detection: MalwareDetection):
        """Detect malware using YARA rules"""
        if not self.yara_rules:
            return

        try:
            matches = self.yara_rules.match(data=file_data)
            for match in matches:
                detection.yara_matches.append(
                    {
                        "rule": match.rule,
                        "namespace": match.namespace,
                        "tags": match.tags,
                        "strings": [
                            {"offset": s[0], "identifier": s[1], "data": s[2]}
                            for s in match.strings
                        ],
                    }
                )
                detection.detection_methods.append(DetectionMethod.YARA.value)

                # Extract malware family from rule tags
                for tag in match.tags:
                    if tag.lower() in [f.value for f in MalwareFamily]:
                        if tag.lower() not in detection.malware_families:
                            detection.malware_families.append(tag.lower())

            logger.info(f"YARA detected {len(matches)} rule matches")
        except Exception as e:
            logger.error(f"YARA detection error: {e}")

    def _detect_behavioral(
        self, ghidra_analysis: Dict[str, Any], detection: MalwareDetection
    ):
        """Detect malware based on behavioral patterns"""
        if not ghidra_analysis:
            return

        # Extract API calls from Ghidra analysis
        api_calls = set()
        if "functions" in ghidra_analysis:
            for func in ghidra_analysis["functions"]:
                if "calls" in func:
                    api_calls.update(func["calls"])

        # Check against known behavior patterns
        for pattern in self.behavior_patterns:
            if self._match_pattern(pattern, api_calls, ghidra_analysis):
                detection.behaviors.append(pattern)
                detection.detection_methods.append(DetectionMethod.BEHAVIORAL.value)

                if pattern.mitre_technique:
                    tactic = self._get_mitre_tactic(pattern.mitre_technique)
                    if tactic not in detection.mitre_tactics:
                        detection.mitre_tactics.append(tactic)

        logger.info(f"Detected {len(detection.behaviors)} behavioral patterns")

    def _match_pattern(
        self,
        pattern: BehaviorPattern,
        api_calls: Set[str],
        analysis: Dict[str, Any],
    ) -> bool:
        """Check if a behavioral pattern matches the sample"""
        if pattern.pattern_type == "api_sequence":
            # Check if all indicators are present in API calls
            matches = sum(
                1 for indicator in pattern.indicators if indicator in api_calls
            )
            threshold = len(pattern.indicators) * 0.6  # 60% match threshold
            return matches >= threshold

        elif pattern.pattern_type == "registry":
            # Check for registry operations
            strings = analysis.get("strings", [])
            return any(
                re.search(indicator, s, re.IGNORECASE)
                for indicator in pattern.indicators
                for s in strings
            )

        elif pattern.pattern_type == "network":
            return any(indicator in api_calls for indicator in pattern.indicators)

        return False

    def _get_mitre_tactic(self, technique_id: str) -> str:
        """Map MITRE technique to tactic"""
        # Simplified mapping
        technique_map = {
            "T1486": "Impact",
            "T1056": "Collection",
            "T1055": "Defense Evasion",
            "T1003": "Credential Access",
            "T1547": "Persistence",
            "T1071": "Command and Control",
        }

        # Extract technique number (e.g., T1055.001 -> T1055)
        base_technique = technique_id.split(".")[0]
        return technique_map.get(base_technique, "Unknown")

    def _check_threat_intel(self, sha256: str, md5: str, detection: MalwareDetection):
        """Check sample against threat intelligence feeds"""
        # Placeholder for threat intelligence lookup
        # In production, this would query services like VirusTotal, MISP, etc.

        # Check local cache
        if sha256 in self.threat_intel_cache:
            intel = self.threat_intel_cache[sha256]
            detection.detection_methods.append(DetectionMethod.THREAT_INTEL.value)

            if intel.get("malicious", False):
                detection.malware_families.extend(intel.get("families", []))
                detection.confidence_score += 0.3

        logger.debug("Threat intelligence check complete")

    def _detect_with_ml(
        self,
        file_data: bytes,
        ghidra_analysis: Optional[Dict[str, Any]],
        detection: MalwareDetection,
    ):
        """Detect malware using machine learning model"""
        if not self.ml_model:
            return

        try:
            # Extract features from binary and analysis
            features = self._extract_ml_features(file_data, ghidra_analysis)

            # Run prediction (placeholder)
            # prediction = self.ml_model.predict([features])
            # confidence = self.ml_model.predict_proba([features])[0][1]

            # For now, use heuristic-based pseudo-ML
            score = self._heuristic_score(features)
            if score > 0.5:
                detection.detection_methods.append(DetectionMethod.ML_MODEL.value)
                detection.confidence_score += score * 0.2

        except Exception as e:
            logger.error(f"ML detection error: {e}")

    def _extract_ml_features(
        self, file_data: bytes, ghidra_analysis: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Extract features for ML model"""
        features = {
            "file_size": len(file_data),
            "entropy": self._calculate_entropy(file_data),
            "printable_ratio": sum(32 <= b < 127 for b in file_data) / len(file_data),
        }

        if ghidra_analysis:
            features["num_functions"] = len(ghidra_analysis.get("functions", []))
            features["num_imports"] = len(ghidra_analysis.get("imports", []))
            features["num_exports"] = len(ghidra_analysis.get("exports", []))
            features["num_strings"] = len(ghidra_analysis.get("strings", []))

        return features

    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy of data"""
        if not data:
            return 0.0

        entropy = 0.0
        byte_counts = [0] * 256

        for byte in data:
            byte_counts[byte] += 1

        data_len = len(data)
        for count in byte_counts:
            if count == 0:
                continue
            probability = count / data_len
            entropy -= probability * (probability.bit_length() - 1)

        return entropy

    def _heuristic_score(self, features: Dict[str, Any]) -> float:
        """Calculate heuristic malware score"""
        score = 0.0

        # High entropy suggests encryption/packing
        entropy = features.get("entropy", 0)
        if entropy > 7.5:
            score += 0.3
        elif entropy > 7.0:
            score += 0.2

        # Unusual file size
        file_size = features.get("file_size", 0)
        if file_size < 10000 or file_size > 10000000:
            score += 0.1

        # Low printable ratio suggests packed/encrypted
        printable_ratio = features.get("printable_ratio", 0)
        if printable_ratio < 0.1:
            score += 0.2

        return min(score, 1.0)

    def _detect_packer(self, file_data: bytes, detection: MalwareDetection):
        """Detect if binary is packed"""
        entropy = self._calculate_entropy(file_data)

        # High entropy suggests packing
        if entropy > 7.5:
            detection.obfuscated = True

        # Check for known packer signatures
        for packer_name, signature in self.known_packers.items():
            if "signature" in signature:
                if signature["signature"] in file_data:
                    detection.packer_detected = packer_name
                    logger.info(f"Detected packer: {packer_name}")
                    return

            if "strings" in signature:
                for string in signature["strings"]:
                    if string.encode() in file_data:
                        detection.packer_detected = packer_name
                        logger.info(f"Detected packer: {packer_name}")
                        return

        if entropy > 7.5 and not detection.packer_detected:
            detection.packer_detected = "unknown"

    def _detect_anti_analysis(
        self,
        file_data: bytes,
        ghidra_analysis: Optional[Dict[str, Any]],
        detection: MalwareDetection,
    ):
        """Detect anti-analysis techniques"""
        if not ghidra_analysis:
            return

        # Extract API calls and strings
        api_calls = set()
        if "functions" in ghidra_analysis:
            for func in ghidra_analysis["functions"]:
                if "calls" in func:
                    api_calls.update(func["calls"])

        strings = ghidra_analysis.get("strings", [])

        # Check for anti-analysis techniques
        for technique, indicators in self.anti_analysis_techniques.items():
            matches = []

            for indicator in indicators:
                if any(indicator in api_call for api_call in api_calls):
                    matches.append(indicator)
                elif any(indicator.lower() in s.lower() for s in strings):
                    matches.append(indicator)

            if matches:
                detection.anti_analysis.append(technique)
                logger.info(f"Detected {technique}: {matches[:3]}")

    def _extract_capabilities(
        self, ghidra_analysis: Optional[Dict[str, Any]], detection: MalwareDetection
    ):
        """Extract malware capabilities from analysis"""
        if not ghidra_analysis:
            return

        # Map API calls to capabilities
        capability_map = {
            "file_operations": ["CreateFile", "WriteFile", "ReadFile", "DeleteFile"],
            "network": ["connect", "send", "recv", "InternetOpen"],
            "registry": ["RegOpenKey", "RegSetValue", "RegQueryValue"],
            "process": ["CreateProcess", "OpenProcess", "TerminateProcess"],
            "crypto": ["CryptAcquireContext", "CryptEncrypt", "CryptDecrypt"],
            "persistence": ["CreateService", "RegSetValue"],
            "privilege_escalation": [
                "AdjustTokenPrivileges",
                "ImpersonateLoggedOnUser",
            ],
        }

        api_calls = set()
        if "functions" in ghidra_analysis:
            for func in ghidra_analysis["functions"]:
                if "calls" in func:
                    api_calls.update(func["calls"])

        for capability, apis in capability_map.items():
            if any(api in api_calls for api in apis):
                if capability not in detection.capabilities:
                    detection.capabilities.append(capability)

    def _classify_malware(self, detection: MalwareDetection):
        """Classify malware into families based on detected patterns"""
        # Use behavior patterns to infer malware family
        family_indicators = {
            MalwareFamily.RANSOMWARE: ["crypto", "file_operations"],
            MalwareFamily.TROJAN: ["network", "persistence"],
            MalwareFamily.SPYWARE: ["keylogger"],
            MalwareFamily.RAT: ["network", "process", "file_operations"],
            MalwareFamily.INFOSTEALER: ["file_operations", "crypto"],
            MalwareFamily.CRYPTOMINER: ["crypto", "privilege_escalation"],
        }

        for family, required_caps in family_indicators.items():
            matches = sum(1 for cap in required_caps if cap in detection.capabilities)
            if matches >= len(required_caps) * 0.5:  # 50% threshold
                if family.value not in detection.malware_families:
                    detection.malware_families.append(family.value)

        # Check behavior patterns
        for behavior in detection.behaviors:
            if "ransomware" in behavior.pattern_id.lower():
                if MalwareFamily.RANSOMWARE.value not in detection.malware_families:
                    detection.malware_families.append(MalwareFamily.RANSOMWARE.value)
            elif "keylogger" in behavior.pattern_id.lower():
                if MalwareFamily.SPYWARE.value not in detection.malware_families:
                    detection.malware_families.append(MalwareFamily.SPYWARE.value)

    def _calculate_threat_level(self, detection: MalwareDetection):
        """Calculate final threat level and confidence score"""
        score = detection.confidence_score

        # Add score based on detections
        if detection.yara_matches:
            score += 0.3

        if detection.behaviors:
            score += len(detection.behaviors) * 0.1

        if detection.anti_analysis:
            score += 0.2

        if detection.packer_detected:
            score += 0.15

        # Determine threat level
        if score >= 0.8:
            detection.threat_level = ThreatLevel.CRITICAL
        elif score >= 0.6:
            detection.threat_level = ThreatLevel.MALICIOUS
        elif score >= 0.3:
            detection.threat_level = ThreatLevel.SUSPICIOUS
        else:
            detection.threat_level = ThreatLevel.BENIGN

        detection.confidence_score = min(score, 1.0)

    def export_report(
        self, detection: MalwareDetection, output_path: str, format: str = "json"
    ):
        """Export malware detection report"""
        report = {
            "sample_hash": detection.sample_hash,
            "threat_level": detection.threat_level.value,
            "confidence_score": detection.confidence_score,
            "malware_families": detection.malware_families,
            "detection_methods": detection.detection_methods,
            "capabilities": detection.capabilities,
            "packer": detection.packer_detected,
            "obfuscated": detection.obfuscated,
            "anti_analysis": detection.anti_analysis,
            "iocs": [
                {
                    "type": ioc.ioc_type,
                    "value": ioc.value,
                    "description": ioc.description,
                    "confidence": ioc.confidence,
                }
                for ioc in detection.iocs
            ],
            "behaviors": [
                {
                    "id": b.pattern_id,
                    "type": b.pattern_type,
                    "description": b.description,
                    "severity": b.severity,
                    "mitre_technique": b.mitre_technique,
                }
                for b in detection.behaviors
            ],
            "yara_matches": detection.yara_matches,
            "mitre_tactics": detection.mitre_tactics,
            "timestamp": detection.timestamp,
        }

        if format == "json":
            with open(output_path, "w") as f:
                json.dump(report, f, indent=2)
        else:
            raise ValueError(f"Unsupported format: {format}")

        logger.info(f"Report exported to {output_path}")


# Example usage
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    # Create detector
    config = MalwareConfig(
        enable_yara=True,
        enable_ml_detection=True,
        enable_behavioral=True,
        confidence_threshold=0.7,
    )
    detector = MalwareDetector(config)

    # Analyze sample
    try:
        detection = detector.analyze_sample("/path/to/sample.exe")
        print(f"Threat Level: {detection.threat_level.value}")
        print(f"Confidence: {detection.confidence_score:.2%}")
        print(f"Families: {', '.join(detection.malware_families)}")
        print(f"Capabilities: {', '.join(detection.capabilities)}")
    except Exception as e:
        print(f"Error: {e}")
